{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DocQA","text":""},{"location":"pages/api/","title":"API","text":"<p>This document describes the REST API for the Document Question-Answering service. The API allows users to upload documents, index them into a searchable knowledge base, and retrieve answers grounded strictly in the document content.</p>"},{"location":"pages/api/#endpoints","title":"Endpoints","text":""},{"location":"pages/api/#post-upload-document","title":"POST <code>/upload-document</code>","text":"<p>Performs asynchronous ingestion and indexing; supports a synchronous mode for small files via a query parameter (e.g. ?sync=true).</p> <ul> <li>Accepts multipart/form-data with a file (PDF or JSON).</li> <li>Returns: {}\"doc_id\": \"\", \"ingest_status\": \"queued\"}."},{"location":"pages/api/#get-statusdoc_id","title":"GET <code>/status/{doc_id}</code>","text":"<p>Returns ingest/indexing status, queued tasks, and basic metadata.</p>"},{"location":"pages/api/#get-docsdoc_idmetadata","title":"GET <code>/docs/{doc_id}/metadata</code>","text":"<p>Returns stored metadata, file hash, vector index statistics and ingest timestamps.</p>"},{"location":"pages/api/#post-questions","title":"POST <code>/questions</code>","text":"<p>Answer a user question by retrieving most relevant chunks from the vector db and framing the answer using LLM.</p> <ul> <li>Accepts JSON: { \"doc_id\": \"\", \"questions\": [\"q1\", \"q2\", ...], \"retrieval\": { \"top_k\": 5 } } or a JSON file upload of questions. <li>Returns structured JSON mapping each question to answer, sources and confidence scores.</li>"},{"location":"pages/api/#example-output","title":"Example Output","text":"<p>Following is the output for each question provided in the json.</p> <pre><code>{\n    \"question\": \"Which cloud providers do you rely on?\",\n    \"answer\": \"We rely on Amazon Web Services (primary) and Google Cloud Platform (backup), as documented on page 12.\",\n    \"sources\": [\n        { \"doc_id\": \"abc\", \"page\": 12, \"chunk_index\": 3, \"text_snippet\": \"...we run on AWS...\", \"score\": 0.92 }\n    ],\n    \"confidence\": 0.87,\n    \"model\": \"gpt-4o-mini\"\n}\n</code></pre>"},{"location":"pages/architecture/","title":"Architecture","text":""},{"location":"pages/user-requirement/","title":"User Requirements","text":"<p>This API is a document-based Question Answering service that allows users to upload a document (PDF or JSON) that serves as a knowledge base. The API processes the document, converts its content into searchable embeddings using a vector database, and answers each question strictly based on the document\u2019s information. It returns the results as a JSON object mapping each question to its corresponding answer, enabling automated analysis, compliance checks, and knowledge extraction from documents.</p>"},{"location":"pages/user-requirement/#user-roles","title":"User Roles","text":"<p>User roles refers to the people who would be interacting with the API. We will define 2 roles - <code>Developer</code>: A user who uploads the documents to form the knowledge base.  - <code>Consumer</code>: A user who would be asking question by passing the json objects. </p>"},{"location":"pages/user-requirement/#functional-requirements","title":"Functional Requirements","text":""},{"location":"pages/user-requirement/#1-inputs","title":"1. Inputs","text":"<ul> <li>Accept PDF and JSON files only; reject all other formats with HTTP 415.</li> <li>Enforce a configurable maximum file size (default: 50 MB); return HTTP 413 if exceeded.</li> <li>Extract and normalize text from PDF and JSON inputs.</li> </ul>"},{"location":"pages/user-requirement/#2-text-processing","title":"2. Text Processing","text":"<ul> <li>Chunk text using configurable chunk size and overlap.</li> <li>Preserve minimal metadata per chunk:</li> <li><code>doc_id</code></li> <li><code>page</code> (if applicable)</li> <li><code>chunk_index</code></li> </ul>"},{"location":"pages/user-requirement/#3-embeddings-storage","title":"3. Embeddings &amp; Storage","text":"<ul> <li>Generate embeddings using a configurable provider (<code>OpenAI</code>).</li> <li>Store embeddings in a Vector Database (<code>FAISS</code>).</li> <li>Persist chunk metadata alongside each vector for traceability.</li> </ul>"},{"location":"pages/user-requirement/#4-retrieval-answering","title":"4. Retrieval &amp; Answering","text":"<ul> <li>Perform top-k semantic retrieval per question.</li> <li>Generate answers using a Retrieval-Augmented Generation (RAG) pipeline with a large language model.</li> <li>Answers must be grounded strictly in retrieved content by citing the source.</li> </ul>"}]}