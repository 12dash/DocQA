{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a982b0-eafb-47f4-a3f6-5636bef4e0c6",
   "metadata": {},
   "source": [
    "# DocQA MVP\n",
    "I created this notebook to demonstrate the **core Retrieval-Augmented Generation (RAG)** workflow that became the foundation of the `DocQA` package. I made a deliberate decision to use **Ollama** during experimentation so I could iterate quickly without spending OpenAI credits. The components are designed to be **modular**, so I can easily swap Ollama for **OpenAI (or any other provider)** later by changing the LLM and embedding implementations—without rewriting the pipeline.\n",
    "\n",
    "**Topics**\n",
    "\n",
    "1. Load documents (**PDF** + **JSON**)\n",
    "2. Split into chunks\n",
    "3. Embed chunks and store in a **Vector DB (FAISS)**\n",
    "4. Retrieve top‑K similar chunks for a question\n",
    "5. Generate an answer with an LLM (**Ollama**)\n",
    "\n",
    "**Local Setup for Ollama**\n",
    "\n",
    "I run Ollama locally and pull the models I need:\n",
    "\n",
    "```bash\n",
    "ollama serve\n",
    "ollama pull qwen2.5:7b\n",
    "ollama pull nomic-embed-text\n",
    "``` \n",
    "\n",
    "Models used :\n",
    "* `qwen2.5:7b` → answer generation\n",
    "* `nomic-embed-text` → embeddings for vector search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f9e091-c347-4cd4-82be-ace2b58828e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997fa00-3e05-4283-8712-143c57c758ab",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc083d7d-2128-47ff-af1a-e80bf160cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_to_json(file):\n",
    "    df = pd.read_csv(f\"../../documents/{file}.csv\", index_col=0)\n",
    "    df = df.fillna(\"\")\n",
    "    records = df.to_dict(orient=\"records\")\n",
    "    with open(f\"../../documents/{file}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c3482f-23b5-4fdc-917c-2fd151e6ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_csv_to_json(\"sample_json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfcef2b-8bc2-4eec-9668-a3b57671c2dd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a1c42-c5e6-4920-83d5-f4d1d5eea741",
   "metadata": {},
   "source": [
    "Ollama Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d42f7640-096e-4394-b9e0-dc794de7efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = \"qwen2.5:7b\"\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "TEMPERATURE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f02eea-1807-4873-a23b-4716ec6bd369",
   "metadata": {},
   "source": [
    "Retriever Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82710e9-5fc1-4b3e-a128-cd29134edaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAISS_INDEX_DIR = Path(\"./faiss_index\")\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "TOP_K = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87de8a00-e7ce-46b0-af60-a08eb34534ba",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac0558f9-6697-4eb0-b1a0-9fc1bc42897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3be695c4-4c36-481d-b215-0653968cd642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(path: str) -> list[Document]:\n",
    "    \"\"\"Loads a pdf\"\"\"\n",
    "    loader = PyPDFLoader(path)\n",
    "    pages = loader.load()\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88820545-37ed-4bcd-9b60-f2cf00734d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> List[Document]:\n",
    "    \"\"\"Loads a json\"\"\"\n",
    "    data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
    "    docs: List[Document] = []\n",
    "\n",
    "    for item in data:\n",
    "        text = (\n",
    "            f\"Question: {item.get('question','')}\\n\"\n",
    "            f\"Answer: {item.get('answer','')}\\n\"\n",
    "            f\"Comments: {item.get('comments','')}\\n\"\n",
    "        )\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=text,\n",
    "                metadata={\"id\": item.get(\"id\"), \"source\": path}\n",
    "            )\n",
    "        )\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc186fc-d87e-4666-bb54-d3613dedcd28",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32658fe2-08e5-46e2-8287-e91b3b2a12d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(\n",
    "    docs: List[Document],\n",
    "    chunk_size: int = CHUNK_SIZE,\n",
    "    overlap: int = CHUNK_OVERLAP,\n",
    ") -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=overlap,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    return splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755a60c-4be5-45eb-97cb-1fa5eceb8b90",
   "metadata": {},
   "source": [
    "## Creating Embeddings + Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6778a19-4b61-4629-bb8b-3a330ac943d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0de0e5-2c13-4917-8e9e-368e5fe04e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_or_load_faiss(\n",
    "    chunks: List[Document],\n",
    "    index_dir: Path = FAISS_INDEX_DIR,\n",
    ") -> FAISS:\n",
    "    \"\"\"Create FAISS index if missing; otherwise load and add documents.\"\"\"\n",
    "    if index_dir.exists():\n",
    "        vs = FAISS.load_local(\n",
    "            str(index_dir),\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True,\n",
    "        )\n",
    "        vs.add_documents(chunks)\n",
    "    else:\n",
    "        vs = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "    vs.save_local(str(index_dir))\n",
    "    return vs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a0364-274d-4b2b-8934-e7088a40ae81",
   "metadata": {},
   "source": [
    "##  Retrieval Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "768e2d32-eacd-4ef3-9591-fb8bd4a8a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_scores(\n",
    "    vector_store: FAISS,\n",
    "    query: str,\n",
    "    k: int = TOP_K,\n",
    ") -> List[Tuple[Document, float]]:\n",
    "    return vector_store.similarity_search_with_score(query, k=k)\n",
    "\n",
    "\n",
    "def format_context(docs_and_scores: List[Tuple[Document, float]]) -> str:\n",
    "    \"\"\"\n",
    "        Creates the context from the retrieved sources by appending metadata and citation for the downstream LLM to answer\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for i, (doc, score) in enumerate(docs_and_scores, 1):\n",
    "        meta = doc.metadata or {}\n",
    "        cite = []\n",
    "        \n",
    "        if meta.get(\"source_type\") == \"pdf\":\n",
    "            if \"page\" in meta:\n",
    "                cite.append(f\"page={meta['page']}\")\n",
    "        \n",
    "        if meta.get(\"source_type\") == \"json\" and meta.get(\"id\"):\n",
    "            cite.append(f\"id={meta['id']}\")\n",
    "        \n",
    "        cite_str = \", \".join(cite) if cite else \"no-meta\"\n",
    "        \n",
    "        parts.append(\n",
    "            f\"[{i}] ({cite_str}, score={score:.4f})\\n{doc.page_content}\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a10aa20c-8692-4fc3-8f0f-2f9ee15c7ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=LLM_MODEL, temperature=TEMPERATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b61cac8-99de-4629-a4e8-03e5754b8d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one(query: str, context: str) -> str:\n",
    "    prompt = f\"\"\"You are a security and compliance documentation assistant.\n",
    "\n",
    "Answer the question using ONLY the information below.\n",
    "Rules:\n",
    "- Do NOT use external knowledge.\n",
    "- Do NOT guess or infer.\n",
    "- If the answer is not clearly present, respond exactly with: Data not found.\n",
    "\n",
    "Information:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    resp = llm.invoke(prompt)\n",
    "    return resp.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25f8879-2438-4184-a6e0-cb53b2e496d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded docs: pdf=56, json=19\n",
      "Chunks: 212\n",
      "Index ready. Elapsed: 6.03s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "pdf_docs = load_pdf(\"../../documents/soc2-type2.pdf\")\n",
    "json_docs = load_json(\"../../documents/sample_json.json\")\n",
    "\n",
    "all_docs = pdf_docs + json_docs\n",
    "splits = split_documents(all_docs)\n",
    "\n",
    "vector_store = build_or_load_faiss(splits)\n",
    "\n",
    "print(f\"Loaded docs: pdf={len(pdf_docs)}, json={len(json_docs)}\")\n",
    "print(f\"Chunks: {len(splits)}\")\n",
    "print(f\"Index ready. Elapsed: {time.time() - t0:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c08e6d9-31c7-4135-8497-7d45215a84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 50}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6669efe-098b-4560-b93d-cd13bfec95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which cloud providers do you rely on?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebc4cc92-cf2b-47be-a9a2-5bb5d26238ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_and_scores = retrieve_with_scores(vector_store, query, k=TOP_K)\n",
    "context = format_context(docs_and_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e139abb3-b342-48b3-978d-b8bb7859c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] (no-meta, score=0.7132)\n",
      "2 \n",
      "INDEPENDENT SERVICE AUDITOR’S REPORT \n",
      " \n",
      "To Board of Directors \n",
      "Product Fruits s.r.o. \n",
      " \n",
      "Scope \n",
      " \n",
      "We have examined the accompanying “ Description of Product Fruits , a cloud -hosted software application ” \n",
      "provided by Product Fruits s.r.o. throughout the period July 24, 2024 to July 23, 2025  (the description) and the \n",
      "suitability of the design and operating effectiveness of controls to meet Product Fruits s.r.o. ’s service \n",
      "commitments and system requirements based on the criteria for Security, Confidentiality, Availability, Processing \n",
      "Integrity & Privacy principles set forth in TSP Section  100 Principles and Criteria, Trust Services Principles and \n",
      "Criteria for Security, Confidentiality and Availability (applicable trust services criteria) throughout the period July \n",
      "24, 2024 to July 23, 2025. \n",
      " \n",
      "Product Fruits s.r.o.  uses Amazon Web Services Inc. (AWS), a subservice organization, to provide cloud\n",
      "\n",
      "[2] (no-meta, score=0.7132)\n",
      "2 \n",
      "INDEPENDENT SERVICE AUDITOR’S REPORT \n",
      " \n",
      "To Board of Directors \n",
      "Product Fruits s.r.o. \n",
      " \n",
      "Scope \n",
      " \n",
      "We have examined the accompanying “ Description of Product Fruits , a cloud -hosted software application ” \n",
      "provided by Product Fruits s.r.o. throughout the period July 24, 2024 to July 23, 2025  (the description) and the \n",
      "suitability of the design and operating effectiveness of controls to meet Product Fruits s.r.o. ’s service \n",
      "commitments and system requirements based on the criteria for Security, Confidentiality, Availability, Processing \n",
      "Integrity & Privacy principles set forth in TSP Section  100 Principles and Criteria, Trust Services Principles and \n",
      "Criteria for Security, Confidentiality and Availability (applicable trust services criteria) throughout the period July \n",
      "24, 2024 to July 23, 2025. \n",
      " \n",
      "Product Fruits s.r.o.  uses Amazon Web Services Inc. (AWS), a subservice organization, to provide cloud\n",
      "\n",
      "[3] (no-meta, score=0.7132)\n",
      "2 \n",
      "INDEPENDENT SERVICE AUDITOR’S REPORT \n",
      " \n",
      "To Board of Directors \n",
      "Product Frui\n"
     ]
    }
   ],
   "source": [
    "print(context[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9f4e0bc-28a5-41fa-9776-bc113ce98ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = answer_one(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87eda70-5875-496e-b873-ec859809ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Fruits s.r.o. relies on Amazon Web Services Inc. (AWS) as a cloud provider.\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
